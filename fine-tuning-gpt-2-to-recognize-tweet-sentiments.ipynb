{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sharooqfarzeenak/fine-tuning-gpt-2-to-recognize-tweet-sentiments?scriptVersionId=211234217\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\n\nos.environ['TOKENIZERS_PARALLELISM'] = \"false\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T16:51:56.843279Z","iopub.execute_input":"2024-12-04T16:51:56.843934Z","iopub.status.idle":"2024-12-04T16:51:56.847791Z","shell.execute_reply.started":"2024-12-04T16:51:56.8439Z","shell.execute_reply":"2024-12-04T16:51:56.84687Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install datasets pandas transformers evaluate numpy torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T16:52:07.596693Z","iopub.execute_input":"2024-12-04T16:52:07.597026Z","iopub.status.idle":"2024-12-04T16:52:17.223289Z","shell.execute_reply.started":"2024-12-04T16:52:07.596997Z","shell.execute_reply":"2024-12-04T16:52:17.222381Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.26.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Loading and analyzing the dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:21:05.223301Z","iopub.execute_input":"2024-12-04T11:21:05.22379Z","iopub.status.idle":"2024-12-04T11:21:07.445996Z","shell.execute_reply.started":"2024-12-04T11:21:05.223732Z","shell.execute_reply":"2024-12-04T11:21:07.445112Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"dataset = load_dataset(\"mteb/tweet_sentiment_extraction\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:21:07.447858Z","iopub.execute_input":"2024-12-04T11:21:07.448461Z","iopub.status.idle":"2024-12-04T11:21:10.653245Z","shell.execute_reply.started":"2024-12-04T11:21:07.448417Z","shell.execute_reply":"2024-12-04T11:21:10.652416Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/22.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d086cc0c23f7489585aced4bc548293b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.jsonl:   0%|          | 0.00/3.63M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41ad4edf3f214d68bea1e09170728526"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.jsonl:   0%|          | 0.00/465k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67e3488e0bc64edea46e656467929fd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/27481 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54ce303297f742f9956d8e1f1e29e023"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3534 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b76be4c9c1b2448c9ea4ce15f315d51d"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:21:10.654219Z","iopub.execute_input":"2024-12-04T11:21:10.654593Z","iopub.status.idle":"2024-12-04T11:21:10.660502Z","shell.execute_reply.started":"2024-12-04T11:21:10.654567Z","shell.execute_reply":"2024-12-04T11:21:10.659658Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'text', 'label', 'label_text'],\n        num_rows: 27481\n    })\n    test: Dataset({\n        features: ['id', 'text', 'label', 'label_text'],\n        num_rows: 3534\n    })\n})"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"dataset['train']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:21:10.662219Z","iopub.execute_input":"2024-12-04T11:21:10.662459Z","iopub.status.idle":"2024-12-04T11:21:10.672244Z","shell.execute_reply.started":"2024-12-04T11:21:10.662436Z","shell.execute_reply":"2024-12-04T11:21:10.671319Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'text', 'label', 'label_text'],\n    num_rows: 27481\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(dataset['train'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:21:10.673216Z","iopub.execute_input":"2024-12-04T11:21:10.673512Z","iopub.status.idle":"2024-12-04T11:21:11.647866Z","shell.execute_reply.started":"2024-12-04T11:21:10.673478Z","shell.execute_reply":"2024-12-04T11:21:11.646822Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:21:11.64928Z","iopub.execute_input":"2024-12-04T11:21:11.649834Z","iopub.status.idle":"2024-12-04T11:21:11.66583Z","shell.execute_reply.started":"2024-12-04T11:21:11.649793Z","shell.execute_reply":"2024-12-04T11:21:11.664989Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"           id                                               text  label  \\\n0  cb774db0d1                I`d have responded, if I were going      1   \n1  549e992a42      Sooo SAD I will miss you here in San Diego!!!      0   \n2  088c60f138                          my boss is bullying me...      0   \n3  9642c003ef                     what interview! leave me alone      0   \n4  358bd9e861   Sons of ****, why couldn`t they put them on t...      0   \n\n  label_text  \n0    neutral  \n1   negative  \n2   negative  \n3   negative  \n4   negative  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>label</th>\n      <th>label_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>1</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>0</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>0</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>0</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>0</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:21:11.66698Z","iopub.execute_input":"2024-12-04T11:21:11.667316Z","iopub.status.idle":"2024-12-04T11:21:11.673758Z","shell.execute_reply.started":"2024-12-04T11:21:11.667287Z","shell.execute_reply":"2024-12-04T11:21:11.672726Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Index(['id', 'text', 'label', 'label_text'], dtype='object')"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Tokenizing","metadata":{}},{"cell_type":"code","source":"from transformers import GPT2Tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:21:11.674853Z","iopub.execute_input":"2024-12-04T11:21:11.675095Z","iopub.status.idle":"2024-12-04T11:21:16.362836Z","shell.execute_reply.started":"2024-12-04T11:21:11.675072Z","shell.execute_reply":"2024-12-04T11:21:16.362107Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20d639b238194d83a4fed3a741657bef"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Loading the dataset to train our model\ndataset = load_dataset(\"mteb/tweet_sentiment_extraction\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T12:48:37.644108Z","iopub.execute_input":"2024-12-04T12:48:37.644796Z","iopub.status.idle":"2024-12-04T12:48:38.821268Z","shell.execute_reply.started":"2024-12-04T12:48:37.644747Z","shell.execute_reply":"2024-12-04T12:48:38.82041Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"# Initializing the gpt-2 tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T12:48:38.822748Z","iopub.execute_input":"2024-12-04T12:48:38.823044Z","iopub.status.idle":"2024-12-04T12:48:39.047179Z","shell.execute_reply.started":"2024-12-04T12:48:38.823015Z","shell.execute_reply":"2024-12-04T12:48:39.046209Z"}},"outputs":[],"execution_count":95},{"cell_type":"code","source":"def tokenize(element):\n   return tokenizer(element[\"text\"], padding=\"max_length\", truncation=True)\n\ntokenized_data = dataset.map(tokenize, batched=True, \n                             remove_columns=['id', 'text', 'label', 'label_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T12:48:39.048268Z","iopub.execute_input":"2024-12-04T12:48:39.048538Z","iopub.status.idle":"2024-12-04T12:48:54.438401Z","shell.execute_reply.started":"2024-12-04T12:48:39.048512Z","shell.execute_reply":"2024-12-04T12:48:54.437588Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/27481 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2827130f4f8748b8b8ddd98696005deb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3534 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b78e673d3fd46a2acd9795384a2ca03"}},"metadata":{}}],"execution_count":96},{"cell_type":"code","source":"tokenized_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T12:48:55.84377Z","iopub.execute_input":"2024-12-04T12:48:55.844471Z","iopub.status.idle":"2024-12-04T12:48:55.850579Z","shell.execute_reply.started":"2024-12-04T12:48:55.844434Z","shell.execute_reply":"2024-12-04T12:48:55.849728Z"}},"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 27481\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 3534\n    })\n})"},"metadata":{}}],"execution_count":97},{"cell_type":"markdown","source":"### Checking out the tokenized data","metadata":{}},{"cell_type":"code","source":"tokenized_data[\"train\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T12:49:04.306123Z","iopub.execute_input":"2024-12-04T12:49:04.306461Z","iopub.status.idle":"2024-12-04T12:49:04.313452Z","shell.execute_reply.started":"2024-12-04T12:49:04.306436Z","shell.execute_reply":"2024-12-04T12:49:04.312472Z"}},"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask'],\n    num_rows: 27481\n})"},"metadata":{}}],"execution_count":98},{"cell_type":"code","source":"tokenized_data[\"train\"][\"input_ids\"][0][:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T12:49:13.738235Z","iopub.execute_input":"2024-12-04T12:49:13.738866Z","iopub.status.idle":"2024-12-04T12:49:25.593075Z","shell.execute_reply.started":"2024-12-04T12:49:13.738833Z","shell.execute_reply":"2024-12-04T12:49:25.592228Z"}},"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"[314, 63, 67, 423, 7082]"},"metadata":{}}],"execution_count":99},{"cell_type":"code","source":"tokenized_data[\"train\"][\"attention_mask\"][0][:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T12:49:26.002217Z","iopub.execute_input":"2024-12-04T12:49:26.002611Z","iopub.status.idle":"2024-12-04T12:49:36.364339Z","shell.execute_reply.started":"2024-12-04T12:49:26.002564Z","shell.execute_reply":"2024-12-04T12:49:36.363562Z"}},"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"[1, 1, 1, 1, 1]"},"metadata":{}}],"execution_count":100},{"cell_type":"code","source":"# Extracting train and eval sets from tokenized_data, which is a Dataset dictionary\n# and trimming the dataset to 1000 because of performance limitations\ntokenized_train_dataset = tokenized_data[\"train\"].shuffle(seed=42).select(range(1000))\ntokenized_eval_dataset = tokenized_data[\"test\"].shuffle(seed=42).select(range(1000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:21:35.237532Z","iopub.execute_input":"2024-12-04T11:21:35.237798Z","iopub.status.idle":"2024-12-04T11:21:35.831297Z","shell.execute_reply.started":"2024-12-04T11:21:35.237775Z","shell.execute_reply":"2024-12-04T11:21:35.830496Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Initializing the model","metadata":{}},{"cell_type":"code","source":"# Number of labels in our classification\nnum_labels = len(df['label'].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:21:35.83232Z","iopub.execute_input":"2024-12-04T11:21:35.832639Z","iopub.status.idle":"2024-12-04T11:21:35.840085Z","shell.execute_reply.started":"2024-12-04T11:21:35.832606Z","shell.execute_reply":"2024-12-04T11:21:35.838998Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from transformers import GPT2ForSequenceClassification\n\n# Loading GPT-2 model for fine-tuning\n# number of labels = number of emotions in our dataset\nmodel = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=num_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:21:35.841206Z","iopub.execute_input":"2024-12-04T11:21:35.841529Z","iopub.status.idle":"2024-12-04T11:21:53.000927Z","shell.execute_reply.started":"2024-12-04T11:21:35.841494Z","shell.execute_reply":"2024-12-04T11:21:53.000041Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eae33add54a47278d39459129cc38eb"}},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:21:53.002442Z","iopub.execute_input":"2024-12-04T11:21:53.00295Z","iopub.status.idle":"2024-12-04T11:21:53.009429Z","shell.execute_reply.started":"2024-12-04T11:21:53.002923Z","shell.execute_reply":"2024-12-04T11:21:53.008562Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"GPT2ForSequenceClassification(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2SdpaAttention(\n          (c_attn): Conv1D(nf=2304, nx=768)\n          (c_proj): Conv1D(nf=768, nx=768)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=3072, nx=768)\n          (c_proj): Conv1D(nf=768, nx=3072)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (score): Linear(in_features=768, out_features=3, bias=False)\n)"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"## Creating evaluation method to pass on to trainer","metadata":{}},{"cell_type":"code","source":"import evaluate\nimport numpy as np\n\nmetric = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n   logits, labels = eval_pred\n   predictions = np.argmax(logits, axis=-1)\n   return metric.compute(predictions=predictions, references=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:22:27.546107Z","iopub.execute_input":"2024-12-04T11:22:27.546491Z","iopub.status.idle":"2024-12-04T11:22:28.858347Z","shell.execute_reply.started":"2024-12-04T11:22:27.54646Z","shell.execute_reply":"2024-12-04T11:22:28.857508Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af5406559a14450e95d019f304d9c1d1"}},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"## Fine-Tuning","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:22:28.859811Z","iopub.execute_input":"2024-12-04T11:22:28.860355Z","iopub.status.idle":"2024-12-04T11:22:30.369088Z","shell.execute_reply.started":"2024-12-04T11:22:28.860324Z","shell.execute_reply":"2024-12-04T11:22:30.368363Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"#### TrainingArguments\r\n\r\n##### Parameters\r\n\r\noutput_dir (str) – The output directory where the model predictions and checkpoints will be written.\r\n\r\noverwrite_output_dir (bool, optional, defaults to False) – If True, overwrite the content of the output directory. Use this to continue training if output_dir points to a checkpoint directory.\r\n\r\ndo_train (bool, optional, defaults to False) – Whether to run training or not.\r\n\r\ndo_eval (bool, optional, defaults to False) – Whether to run evaluation on the dev set or not.\r\n\r\ndo_predict (bool, optional, defaults to False) – Whether to run predictions on the test set or not.\r\n\r\nevaluate_during_training (bool, optional, defaults to False) – Whether to run evaluation during training at each logging step or not.\r\n\r\nper_device_train_batch_size (int, optional, defaults to 8) – The batch size per GPU/TPU core/CPU for training.\r\n\r\nper_device_eval_batch_size (int, optional, defaults to 8) – The batch size per GPU/TPU core/CPU for evaluation.\r\n\r\ngradient_accumulation_steps – (int, optional, defaults to 1): Number of updates steps to accumulate the gradients for, before performing a backward/update pass.\r\n\r\nlearning_rate (float, optional, defaults to 5e-5) – The initial learning rate for Adam.\r\n\r\nweight_decay (float, optional, defaults to 0) – The weight decay to apply (if not zero).\r\n\r\nadam_epsilon (float, optional, defaults to 1e-8) – Epsilon for the Adam optimizer.\r\n\r\nmax_grad_norm (float, optional, defaults to 1.0) – Maximum gradient norm (for gradient clipping).\r\n\r\nnum_train_epochs (float, optional, defaults to 3.0) – Total number of training epochs to perform.\r\n\r\nmax_steps (int, optional, defaults to -1) – If set to a positive number, the total number of training steps to perform. Overrides num_train_epochs.\r\n\r\nwarmup_steps (int, optional, defaults to 0) – Number of steps used for a linear warmup from 0 to learning_rate.\r\n\r\nlogging_dir (str, optional) – Tensorboard log directory. Will default to runs/**CURRENT_DATETIME_HOSTNAME**.\r\n\r\nlogging_first_step (bool, optional, defaults to False) – Wheter to log and evalulate the first global_step or not.\r\n\r\nlogging_steps (int, optional, defaults to 500) – Number of update steps between two logs.\r\n\r\nsave_steps (int, optional, defaults to 500) – Number of updates steps before two checkpoint saves.\r\n\r\nsave_total_limit (int, optional) – If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in output_dir.\r\n\r\nno_cuda (bool, optional, defaults to False) – Wherher to not use CUDA even when it is available or not.\r\n\r\nseed (int, optional, defaults to 42) – Random seed for initialization.\r\n\r\nfp16 (bool, optional, defaults to False) – Whether to use 16-bit (mixed) precision training (through NVIDIA apex) instead of 32-bit training.\r\n\r\nfp16_opt_level (str, optional, defaults to ‘O1’) – For fp16 training, apex AMP optimization level selected in [‘O0’, ‘O1’, ‘O2’, and ‘O3’]. See details on the apex documentation.\r\n\r\nlocal_rank (int, optional, defaults to -1) – During distributed training, the rank of the process.\r\n\r\ntpu_num_cores (int, optional) – When training on TPU, the mumber of TPU cores (automatically passed by launcher script).\r\n\r\ndebug (bool, optional, defaults to False) – When training on TPU, whether to print debug metrics or not.\r\n\r\ndataloader_drop_last (bool, optional, defaults to False) – Whether to drop the last incomplete batch (if the length of the dataset is not divisible by the batch size) or not.\r\n\r\neval_steps (int, optional, defaults to 1000) – Number of update steps between two evaluations.\r\n\r\npast_index (int, optional, defaults to -1) – Some models like TransformerXL or :doc`XLNet <../model_doc/xlnet>` can make use of the past hidden states for their predictions. If this argument is set to a positive int, the Trainer will use the corresponding output (usually index 2) as the past state and feed it to the model at the next training step under the keyword argument mems.del at the next training step under the keyword argument mems.","metadata":{}},{"cell_type":"code","source":"# Configuring the trainer\ntraining_args = TrainingArguments(\n   output_dir=\"test_trainer\",\n   #evaluation_strategy=\"epoch\",\n   per_device_train_batch_size=1,  # Reduce batch size here\n   per_device_eval_batch_size=1,    # Optionally, reduce for evaluation as well\n   gradient_accumulation_steps=4\n   )\n\n\ntrainer = Trainer(\n   model=model,\n   args=training_args,\n   train_dataset=tokenized_train_dataset,\n   eval_dataset=tokenized_eval_dataset,\n   compute_metrics=compute_metrics\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:22:30.370056Z","iopub.execute_input":"2024-12-04T11:22:30.370298Z","iopub.status.idle":"2024-12-04T11:22:32.068857Z","shell.execute_reply.started":"2024-12-04T11:22:30.370274Z","shell.execute_reply":"2024-12-04T11:22:32.068161Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:22:32.069903Z","iopub.execute_input":"2024-12-04T11:22:32.070192Z","iopub.status.idle":"2024-12-04T11:32:24.397447Z","shell.execute_reply.started":"2024-12-04T11:22:32.07014Z","shell.execute_reply":"2024-12-04T11:32:24.396608Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241204_112246-1vl85h2l</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sharooqfarzeen-other/huggingface/runs/1vl85h2l' target=\"_blank\">test_trainer</a></strong> to <a href='https://wandb.ai/sharooqfarzeen-other/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sharooqfarzeen-other/huggingface' target=\"_blank\">https://wandb.ai/sharooqfarzeen-other/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sharooqfarzeen-other/huggingface/runs/1vl85h2l' target=\"_blank\">https://wandb.ai/sharooqfarzeen-other/huggingface/runs/1vl85h2l</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [375/375 09:32, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=375, training_loss=0.9992447916666667, metrics={'train_runtime': 591.9806, 'train_samples_per_second': 5.068, 'train_steps_per_second': 0.633, 'total_flos': 1567794659328000.0, 'train_loss': 0.9992447916666667, 'epoch': 3.0})"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"import evaluate\n\ntrainer.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:32:24.399371Z","iopub.execute_input":"2024-12-04T11:32:24.399643Z","iopub.status.idle":"2024-12-04T11:33:31.017455Z","shell.execute_reply.started":"2024-12-04T11:32:24.399618Z","shell.execute_reply":"2024-12-04T11:33:31.016535Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [500/500 01:06]\n    </div>\n    "},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.8578683137893677,\n 'eval_accuracy': 0.645,\n 'eval_runtime': 66.6052,\n 'eval_samples_per_second': 15.014,\n 'eval_steps_per_second': 7.507,\n 'epoch': 3.0}"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"## Inferencing from the fine-tuned model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer\nimport torch\n\n# Specify the path where the model is saved\nmodel_path = \"/kaggle/working/test_trainer/checkpoint-375\"\n\n# Load the model and tokenizer\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:53:37.443372Z","iopub.execute_input":"2024-12-04T11:53:37.443752Z","iopub.status.idle":"2024-12-04T11:53:37.784855Z","shell.execute_reply.started":"2024-12-04T11:53:37.443722Z","shell.execute_reply":"2024-12-04T11:53:37.783976Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"def predict(tweet):\n\n    # Printing the tweet\n    print(\"Tweet:\",tweet)\n    \n    # Tokenize the input\n    inputs = tokenizer(tweet, return_tensors=\"pt\", truncation=True)\n    \n    # Get predictions\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    # Get the logits (raw model outputs)\n    logits = outputs.logits\n    \n    # Convert logits to probabilities (optional)\n    probabilities = torch.softmax(logits, dim=-1)\n    \n    # Get the predicted class\n    predicted_class = torch.argmax(probabilities, dim=-1).item()\n    \n    print(\"Predicted class:\", predicted_class)\n    \n    # Define the label mapping (example)\n    label_mapping = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n    \n    # Get the human-readable label\n    sentiment = label_mapping[predicted_class]\n    \n    print(f\"Sentiment: {sentiment}\", end=\"\\n\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T12:31:02.380623Z","iopub.execute_input":"2024-12-04T12:31:02.381281Z","iopub.status.idle":"2024-12-04T12:31:02.388167Z","shell.execute_reply.started":"2024-12-04T12:31:02.381247Z","shell.execute_reply":"2024-12-04T12:31:02.387215Z"}},"outputs":[],"execution_count":83},{"cell_type":"markdown","source":"### Preparing data for prediction","metadata":{}},{"cell_type":"code","source":"all_tweets = tokenized_eval_dataset[\"text\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T12:33:16.390811Z","iopub.execute_input":"2024-12-04T12:33:16.391655Z","iopub.status.idle":"2024-12-04T12:33:16.405141Z","shell.execute_reply.started":"2024-12-04T12:33:16.391616Z","shell.execute_reply":"2024-12-04T12:33:16.404216Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"import random\n\ntweets = random.sample(all_tweets, 5)\n\n[predict(tweet) for tweet in tweets]\n\nprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T12:36:21.288086Z","iopub.execute_input":"2024-12-04T12:36:21.288508Z","iopub.status.idle":"2024-12-04T12:36:21.617085Z","shell.execute_reply.started":"2024-12-04T12:36:21.288476Z","shell.execute_reply":"2024-12-04T12:36:21.616167Z"}},"outputs":[{"name":"stdout","text":"Tweet:  D: But it is making people unhappy and I dun like unhappiness\nPredicted class: 0\nSentiment: Negative\n\nTweet: Not made it to work  couldn`t get up feelin blurgh\nPredicted class: 1\nSentiment: Neutral\n\nTweet: stupid wireless!!\nPredicted class: 0\nSentiment: Negative\n\nTweet: shop then work time  see yas laterz x\nPredicted class: 1\nSentiment: Neutral\n\nTweet:  A rare treat b/c we`re rarely ap and at `em that early!  But we may make opening bell at the PDX Farmers Mkt a new goal.\nPredicted class: 1\nSentiment: Neutral\n\n\n","output_type":"stream"}],"execution_count":92}]}